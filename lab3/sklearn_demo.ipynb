{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32f3088b-e2b4-4a62-b450-807eaefa3cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the original code is from https://github.com/bhaswara/CV_24T3/tree/main, created by Irfan Dwiki Bhaswaraimport\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "377d077b-1496-41a6-b6cc-81bf46a653e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digits dictionary content \n",
      "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "# In this demo, we are using MNIST dataset\n",
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "pd = datasets.load_digits()\n",
    "print('Digits dictionary content \\n{}'.format(digits.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "730012fd-557f-48d8-b7d7-46aa68396550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (data, label) in enumerate(images_and_labels[:4]):\n",
    "    imgdim=int(np.sqrt(digits.data[index].shape[0]))\n",
    "    img=np.reshape(digits.data[index],(imgdim,imgdim))\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc845462-a3a3-446c-9157-5ea8764d42d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data and target sizes: \n",
      "(1347, 64), (1347,)\n",
      "Test data and target sizes: \n",
      "(450, 64), (450,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(digits.data,digits.target,test_size=0.25)\n",
    "print('Training data and target sizes: \\n{}, {}'.format(X_train.shape,y_train.shape))\n",
    "print('Test data and target sizes: \\n{}, {}'.format(X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9ba383a-2bc7-4895-a457-705c4a04da7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8622\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94        47\n",
      "           1       0.79      0.79      0.79        48\n",
      "           2       0.86      0.88      0.87        42\n",
      "           3       0.88      0.84      0.86        45\n",
      "           4       0.91      0.85      0.88        47\n",
      "           5       0.98      0.87      0.92        46\n",
      "           6       0.91      0.91      0.91        55\n",
      "           7       0.85      0.80      0.82        35\n",
      "           8       0.71      0.79      0.75        43\n",
      "           9       0.84      0.88      0.86        42\n",
      "\n",
      "    accuracy                           0.86       450\n",
      "   macro avg       0.86      0.86      0.86       450\n",
      "weighted avg       0.87      0.86      0.86       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Using DT\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "dt_predicts = dt.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, dt_predicts)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, dt_predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35e4792-211a-4d69-935e-79ece3cb3867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f321015e-801f-48d0-9254-e5c20b5eec45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.98      1.00      0.99        50\n",
      "           2       1.00      1.00      1.00        38\n",
      "           3       0.94      1.00      0.97        50\n",
      "           4       1.00      1.00      1.00        47\n",
      "           5       1.00      1.00      1.00        38\n",
      "           6       1.00      1.00      1.00        47\n",
      "           7       1.00      0.98      0.99        44\n",
      "           8       1.00      0.98      0.99        43\n",
      "           9       0.98      0.94      0.96        50\n",
      "\n",
      "    accuracy                           0.99       450\n",
      "   macro avg       0.99      0.99      0.99       450\n",
      "weighted avg       0.99      0.99      0.99       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Using KNN\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "knn_predicts = knn.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, knn_predicts)\n",
    "print(f'Accuracy Score: {accuracy:.4f}')\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, knn_predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6552e9df-de4d-412c-8a00-713eae848256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a36c02b6-cb31-4ce5-87ef-68cf4ce0ef22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.96      0.86      0.91        50\n",
      "           2       1.00      0.97      0.99        38\n",
      "           3       0.96      0.96      0.96        50\n",
      "           4       1.00      0.98      0.99        47\n",
      "           5       0.90      0.95      0.92        38\n",
      "           6       1.00      1.00      1.00        47\n",
      "           7       1.00      0.95      0.98        44\n",
      "           8       0.80      0.95      0.87        43\n",
      "           9       0.92      0.90      0.91        50\n",
      "\n",
      "    accuracy                           0.95       450\n",
      "   macro avg       0.95      0.95      0.95       450\n",
      "weighted avg       0.95      0.95      0.95       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "sgd_predicts = sgd.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, sgd_predicts)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, sgd_predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63497c37-9310-4f10-80af-c5b0fe42fb77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8742a8-62f5-4450-9ec6-59693aa00f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Hints and Steps reading Chinese MNIST\n",
    "(1) Use csv file provided to split the dataset according to its classes. \n",
    "    You can create function which take the image path as well as class label\n",
    "(2) To read the image, make sure to read it in grayscale and don't forget to flatten it.\n",
    "(3) Use train_test_split from sklearn to split data. You can directly use your csv file into this. \n",
    "    Make sure to set the random_state to be the same and don't forget to use stratify so your classes have the same number.\n",
    "    You can define the number of training and testing set as well\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "820bff5b-95ff-4866-a070-418c4511b9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suite_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>code</th>\n",
       "      <th>value</th>\n",
       "      <th>character</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>九</td>\n",
       "      <td>input_1_1_10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>九</td>\n",
       "      <td>input_1_10_10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>九</td>\n",
       "      <td>input_1_2_10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>九</td>\n",
       "      <td>input_1_3_10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>九</td>\n",
       "      <td>input_1_4_10.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   suite_id  sample_id  code  value character               file\n",
       "0         1          1    10      9         九   input_1_1_10.jpg\n",
       "1         1         10    10      9         九  input_1_10_10.jpg\n",
       "2         1          2    10      9         九   input_1_2_10.jpg\n",
       "3         1          3    10      9         九   input_1_3_10.jpg\n",
       "4         1          4    10      9         九   input_1_4_10.jpg"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "About Chinese MNIST dataset\n",
    "https://www.kaggle.com/datasets/gpreda/chinese-mnist/data\n",
    "\n",
    "One hundred Chinese nationals took part in data collection. Each participant wrote with a standard black ink pen all 15 numbers \n",
    "in a table with 15 designated regions drawn on a white A4 paper. \n",
    "This process was repeated 10 times with each participant. Each sheet was scanned at the resolution of 300x300 pixels.\n",
    "\n",
    "Code is used to map each single character and it will be the one used for the target variable.\n",
    "Each character is present 1K times (15 characters = 15K entries) with own hand written image.\n",
    "The total number of classes to predict are 15.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "884ac199-fedc-44d2-841b-bcc565e8034b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code  character\n",
       "1     零            1000\n",
       "2     一            1000\n",
       "3     二            1000\n",
       "4     三            1000\n",
       "5     四            1000\n",
       "6     五            1000\n",
       "7     六            1000\n",
       "8     七            1000\n",
       "9     八            1000\n",
       "10    九            1000\n",
       "11    十            1000\n",
       "12    百            1000\n",
       "13    千            1000\n",
       "14    万            1000\n",
       "15    亿            1000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbe66ca-fd23-4e7f-85fd-107e2cce9390",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
